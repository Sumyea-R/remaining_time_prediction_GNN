{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e4eb5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#from pm4py import pm4py\n",
    "from pm4py.objects.conversion.log import converter as xes_converter\n",
    "from pm4py.algo.filtering.log.attributes import attributes_filter\n",
    "from pm4py.objects.log.obj import EventLog, Trace, Event\n",
    "import math\n",
    "import csv\n",
    "from bidict import bidict\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import itertools\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Input\n",
    "from keras.optimizers import Nadam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import BatchNormalization\n",
    "import pre_processing\n",
    "import utility_functions\n",
    "import mappers\n",
    "import vectorize_features\n",
    "import train\n",
    "import prediction\n",
    "import post_processing\n",
    "import evaluation\n",
    "import constants\n",
    "import preprocess_graph_attributes\n",
    "import pickle as pkl\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "223ca8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sumyea/Desktop/Study/Study/WS21-22/Introduction_to_Data_Science/Assignment/Part1/env/lib/python3.8/site-packages/pm4py/util/pandas_utils.py:37: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  return df.to_dict('records')\n"
     ]
    }
   ],
   "source": [
    "# Load and convert the dataset \n",
    "\n",
    "\n",
    "# Import the required attributes from the CSV file\n",
    "df = pd.read_csv('.//logistic_CSS9D_CSS9E.csv')[constants.required_attributes+constants.event_attribute_features+constants.case_attribute+constants.case_attribute]\n",
    "\n",
    "# Convert the DataFrame into the event log structure\n",
    "log = xes_converter.apply(df, variant=xes_converter.Variants.TO_EVENT_LOG) \n",
    "\n",
    "# Convert the timestamp from string to datetime format\n",
    "log = pre_processing.convert_timestamp(log)\n",
    "\n",
    "# Adjust the arrived time\n",
    "#log = pre_processing.adjust_arrived_time(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "135a676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'logistic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15ac8aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "global variables using the entire event log\n",
    "\"\"\"\n",
    "# Calculate the average dwell time in seconds: 245.68552766191863\n",
    "average_dwell_time_in_sec = utility_functions.average_dwell_time(log)\n",
    "\n",
    "# Calculate the average time since case start in seconds: 5737.639253954513\n",
    "average_time_since_start_in_sec = utility_functions.average_time_since_case_start(log)\n",
    "\n",
    "average_time_till_case_end = utility_functions.average_time_till_case_end(log)\n",
    "\n",
    "# Build the mapper for average dwell time based on EQTYP: \n",
    "dwell_time_mapper = mappers.build_average_dwell_time_mapper(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b94ef5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fold creation\n",
    "\"\"\"\n",
    "# Create folds for training and testing\n",
    "folds = pre_processing.create_folds(log, 3)\n",
    "\n",
    "# get the training and validation log log from first two folds\n",
    "train_and_validation = EventLog([case for sub_log in folds[:2] for case in sub_log])\n",
    "\n",
    "training_log = train_and_validation[:int(len(train_and_validation)*0.8)]\n",
    "validation_log = train_and_validation[int(len(train_and_validation)*0.8):]\n",
    "\n",
    "# Use the third fold for testing\n",
    "testing_log = EventLog([case for sub_log in folds[2:] for case in sub_log])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b66d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Global variables using only the training log\n",
    "\"\"\"\n",
    "# Build the mapper for EID based on the training log\n",
    "eid_mapper = mappers.build_eid_mapper(training_log)\n",
    "\n",
    "# Get the maximum case length in the training log and add an end signal\n",
    "max_case_len = max([len(case) for case in training_log]) + 1\n",
    "\n",
    "# Build mappers for event attribute features based on the training log\n",
    "event_attribute_mappers = {attr: mappers.build_event_attr_mapper(training_log, attr) for attr in constants.event_attribute_features}\n",
    "\n",
    "# Build mappers for case attribute features based on the training log\n",
    "case_attribute_mappers = {attr: mappers.build_case_attr_mapper(training_log, attr) for attr in constants.case_attribute_features}\n",
    "\n",
    "# Get the routing netwrok of logistic log\n",
    "network = preprocess_graph_attributes.preprocess_graph_attributes('.//20230906-logistic_nw.gml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bfa9850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize train, test and validation set\n",
    "X_train = vectorize_features.vectorize_features(training_log, average_time_since_start_in_sec, eid_mapper, average_dwell_time_in_sec, event_attribute_mappers, case_attribute_mappers, max_case_len, network, average_time_till_case_end)\n",
    "Y_train = vectorize_features.vectorize_rtm_prediction(training_log, average_time_till_case_end)\n",
    "\n",
    "X_valid = vectorize_features.vectorize_features(validation_log, average_time_since_start_in_sec, eid_mapper, average_dwell_time_in_sec, event_attribute_mappers, case_attribute_mappers, max_case_len, network, average_time_till_case_end)\n",
    "Y_valid = vectorize_features.vectorize_rtm_prediction(validation_log, average_time_till_case_end)\n",
    "\n",
    "X_test = vectorize_features.vectorize_features(testing_log, average_time_since_start_in_sec, eid_mapper, average_dwell_time_in_sec, event_attribute_mappers, case_attribute_mappers, max_case_len, network, average_time_till_case_end)\n",
    "Y_test = vectorize_features.vectorize_rtm_prediction(testing_log, average_time_till_case_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b5d9541",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to save it\n",
    "with open(\"GGNN_\"+data_name+\"_train.pkl\", \"wb\") as f:\n",
    "    pkl.dump([X_train, Y_train], f)\n",
    "with open(\"GGNN_\"+data_name+\"_valid.pkl\", \"wb\") as f:\n",
    "    pkl.dump([X_valid, Y_valid], f)\n",
    "with open(\"GGNN_\"+data_name+\"_test.pkl\", \"wb\") as f:\n",
    "    pkl.dump([X_test, Y_test], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
